\ifx\wholebook\relax \else
% ------------------------ 

\documentclass{article}
%------------------- Other types of document example ------------------------
%
%\documentclass[twocolumn]{IEEEtran-new}
%\documentclass[12pt,twoside,draft]{IEEEtran}
%\documentstyle[9pt,twocolumn,technote,twoside]{IEEEtran}
%
%-----------------------------------------------------------------------------
%\input{../../../common.tex}
\input{../../../common-en.tex}

\setcounter{page}{1}

\begin{document}

\fi
%--------------------------

% ================================================================
%                 COVER PAGE
% ================================================================

\title{K-ary tree and forest Heaps}

\author{Liu~Xinyu
\thanks{{\bfseries Liu Xinyu } \newline
  Email: liuxinyu95@gmail.com \newline}
  }

\markboth{K-ary tree and forest Heaps}{AlgoXY}

\maketitle

\ifx\wholebook\relax
\chapter{K-ary tree and forest Heaps}
\fi

% ================================================================
%                 Introduction
% ================================================================
\section{Introduction}
\label{introduction}
In previous chapter, we mentioned that heaps can be
generalized and implemented with varies of data structures. However,
only binary heaps are focused so far no matter by explicit binary
trees or implicit array. 

It's quite natural to extend the binary tree to K-ary \cite{K-ary-tree} tree. 
In this chapter, we first show Binomial heaps 
which is actually consist of forest of K-ary trees. Binomial heaps gain the 
performance for all operations to $O(\lg N)$, as well as keeping the finding 
minimum element to $O(1)$ time.

If we delay some operations in Binomial
heaps by using lazy strategy, it turns to be Fibonacci heap.
 
All binary heaps we have shown perform
no less than $O(\lg N)$ time for merging, we'll show it's possible to 
improve it to $O(1)$ with Fibonacci heap, which is quite helpful to 
graph algorithms. Actually, Fibonacci heap acheives almost all operations 
to good amortized time bound as $O(1)$,
and left the heap pop to $O(\lg N)$. 

Finally, we'll introduce about the pairing heaps. It has the best performance in practice althought the proof of it is still a conjecture for the time 
being.


% ================================================================
%                 Binomial heap
% ================================================================
\section{Binomial Heaps}
\label{binomail-heap} \index{Binomial heap}


% ================================================================
%                 Definition
% ================================================================
\subsection{Definition}

Binomial heap is more complex than most of the binary heaps. However,
it has excellent merge performance which bound to $O(\lg N)$ time. A
binomial heap is consist of a list of binomial trees.

\subsubsection{Binomial tree}
\label{Binomial tree} \index{Binomial tree}

In order to explain why the name of the tree is `binomial', let's review
the famouse Pascal's triangle (in China, we call it Yang Hui's triangle)
\cite{wiki-pascal-triangle}.

\begin{verbatim}
    1
   1 1
  1 2 1
 1 3 3 1
1 4 6 4 1
...
\end{verbatim}

In each row, the numbers are all binomial coefficients. There are many
ways to gain a series of binomial coefficient numbers. One of them is
by using recusive composition. Binomial trees, as well, can be defined
in this way as the following.

\begin{itemize}
\item A binomial tree of rank 0 has only a node as the root;
\item A binomial tree of rank $N$ is consist of two rank $N-1$ binomail trees,
Among these 2 sub trees, the one has the bigger root element is linked as the
leftmost child of the other.
\end{itemize}

We denote a binomial tree of rank 0 as $B_0$, and the binomial tree of rank
$n$ as $B_n$.

Figure \ref{fig:link-bitree} shows a $B_0$ tree and how to link 2 $B_{n-1}$
trees to a $B_n$ tree.

\begin{figure}[htbp]
  \centering
  \subfloat[A $B_0$ tree.]{\hspace{0.1\textwidth}\includegraphics[scale=0.5]{img/b0tree.ps}\hspace{0.1\textwidth}} \\
  \subfloat[Linking 2 $B_{n-1}$ trees yields a $B_n$ tree.]{\includegraphics[scale=0.5]{img/link-bitree.ps}}
  \caption{Recursive definition of binomial trees} \label{fig:link-bitree}
\end{figure}

With this recursive definition, it easy to draw the form of binomial trees
of rank 0, 1, 2, ..., as shown in figure \ref{fig:bitree-forms}

\begin{figure}[htbp]
  \centering
  \subfloat[$B_0$ tree;]{\hspace{0.05\textwidth}\includegraphics[scale=0.5]{img/b0tree.ps}\hspace{0.05\textwidth}}
  \subfloat[$B_1$ tree;]{\hspace{0.05\textwidth}\includegraphics[scale=0.5]{img/b1tree.ps}\hspace{0.05\textwidth}}
  \subfloat[$B_2$ tree;]{\includegraphics[scale=0.5]{img/b2tree.ps}}
  \subfloat[$B_3$ tree;]{\includegraphics[scale=0.5]{img/b3tree.ps}} \\
  \subfloat[$B_4$ tree;]{\includegraphics[scale=0.5]{img/b4tree.ps}...}
  \caption{Forms of binomial trees with rank = 0, 1, 2, 3, 4, ...} \label{fig:bitree-forms}
\end{figure}

Observing the binomail trees reveals some interesting properties. For each rank $N$ binomial tree, if counting the number of nodes in each row, it can be found that it is the binomial number.

For instance for rank 4 binomail tree, there is 1 node as the root; and in the second level next to root, there are 4 nodes; and in 3rd level, there are 6 nodes; and in 4th level, there are 4 nodes; and the 5th level, there is 1 node. They are exactly 1, 4, 6, 4, 1 which is the 5th row in Pascal's triangle. That's why we call it binomial tree.

Another interesting property is that the total number of node for a binomail tree with rank $N$ is $2^N$. This can be proved either by binomial theory or the recursive definition directly.

\subsubsection{Binomial heap}
\label{Binomial heap} \index{Binomail heap!definition}

With binomial tree defined, we can introduce the definition of binomial heap. A binomial heap is a set of binomail trees (or a forest of binomial trees) that satisfied the following properties.

\begin{itemize}
\item Each binomail tree in the heap conforms to {\em heap property}, that the key of a node is equal or greater than the key of its parent. Here the heap is actually min-heap, for max-heap, it changes to `equal or less than'. In this chapter, we only discuss about min-heap, and max-heap can be equally applied by changing the comparison condition.
\item There is at most one binomail tree which has the rank $r$. In other words, there are no two binomial trees have the same rank.
\end{itemize}

This definition leads to an important result that for a binomial heap contains $N$ elements, and if convert $N$ to binary format yields $a_0, a_1, a_2, ..., a_m$, where $a_0$ is the LSB and $a_m$ is the MSB, then for each $0 \leq i \leq m$, if $a_i=0$, there is no binomial tree of rank $i$ and if $a_i = 1$, there must be a binomial tree of rank $i$.

For example, if a binomial heap contains 5 element, as 5 is `(LSB)101(MSB)', then there are 2 binomial trees in this heap, one tree has rank 0, the other has rank 2.

Figure \ref{fig:bheap2} shows a binomial heap which have 19 nodes, as 19 is `(LSB)11001(MSB)' in binary format, so there is a $B_0$ tree, a $B_1$ tree and a $B_4$ tree.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=0.5]{img/bheap2.ps}
  \caption{A binomial heap with 19 elements} \label{fig:bheap2}
\end{figure}

\subsubsection{Data layout}
\index{left child, right sibling}
There are two ways to define K-ary trees imperatively. One is by using
`left-child, right-sibling' approach\cite{CLRS}. It is compatible with 
the typical binary tree structure. For each node, it has two fields,
left field and right field. We use the left field to point to the first
child of this node, and use the right field to point to the sibling
node of this node. All silbings are represented as a single directional
linked list.

The other way is to use the library defined collection container, such
as array or list to represent all children of a node.

Since the rank of a tree plays very important role, we also defined
it as a field.

For `left-child, right-sibling' method, we defined the binomial tree
as the following.\footnote{C programs are also provided along with this book.}

\lstset{language=Python}
\begin{lstlisting}
class BinomialTree:
    def __init__(self, x = None):
        self.rank = 0
        self.key = x
        self.parent = None
        self.child = None
        self.sibling = None
\end{lstlisting}

When initalize a tree with a key, we create a leaf node, set its rank
as zero and all other fields are set as NIL.

It quite nature to utilize pre-defined list to represent mulitple children
as below.

\begin{lstlisting}
class BinomialTree:
    def __init__(self, x = None):
        self.rank = 0
        self.key = x
        self.parent = None
        self.children = []
\end{lstlisting}

For purely functional settings, such as in Haskell language, binomial tree
are defined as the following.

\lstset{language=Haskell}
\begin{lstlisting}
data BiTree a = Node { rank :: Int
                     , root :: a
                     , children :: [BiTree a]} 
\end{lstlisting}

While binomial heap are defined as a list of binomial trees (a forest) with 
ranks in monotonically increase order. And as another implicit constraint,
there are no two binomial trees have the same rank.

\begin{lstlisting}
type BiHeap a = [BiTree a] 
\end{lstlisting}

% ================================================================
%                 Basic heap operation
% ================================================================
\subsection{Basic heap operations}

\subsubsection{Linking trees}
\index{Binomail Heap!Linking}

Before dive into the basic heap operations such as pop and insert,
We'll first realize how to link two binomial trees with same rank into a
bigger one. According to the definition of binomial tree and heap
property that the root always contains the minimum key, we firstly
compare the two root values, select the smaller one as the new
root, and insert the other tree as the first child in front of
all other children. Suppose function $Key(T)$, $Children(T)$, and
$Rank(T)$ access the key, children and rank of a binomial tree 
respectively.

\be
link(T_1, T_2) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  node(r+1, x, \{ T_2 \} \cup C_1) & x < y \\
  node(r+1, y, \{ T_1 \} \cup C_2) & otherwise 
  \end{array}
\right .
\ee

Where

\[
  \begin{array}{l}
  x = Key(T_1) \\
  y = Key(T_2) \\
  r = Rank(T_1) = Rank(T_2) \\
  C_1 = Children(T_1) \\
  C_2 = Children(T_2)
  \end{array}
\]

\lstset{language=Haskell}
\begin{lstlisting}
link :: (Ord a) => BiTree a -> BiTree a -> BiTree a
link t1@(Node r x c1) t2@(Node _ y c2) = 
    if x<y then Node (r+1) x (t2:c1)
    else Node (r+1) y (t1:c2)
\end{lstlisting}

If we use `left child, right sibling' approach,
this algorithm can be described like the following.


\begin{algorithmic}[1]
\Function{LINK}{$T_1, T_2$}
  \If{$KEY(T_2) < KEY(T_1)$}
    \State Exchange $T_1 \leftrightarrow T_2$
  \EndIf
  \State $SIBLING(T_2) \gets CHILD(T_1)$
  \State $CHILD(T_1) \gets T_2$
  \State $PARENT(T_2) \gets T_1$
  \State $RANK(T_1) \gets RANK(T_1) + 1$
  \State \Return $T_1$
\EndFunction
\end{algorithmic}

And if we use a container to manage all children of a node, the
algorihtm is like below.

\begin{algorithmic}[1]
\Function{LINK'}{$T_1, T_2$}
  \If{$KEY(T_2) < KEY(T_1)$}
    \State Exchange $T_1 \leftrightarrow T_2$
  \EndIf
  \State $PARENT(T_2) \gets T_1$
  \State $INSERT-BEFORE(CHILDREN(T_1), T_2)$
  \State $RANK(T_1) \gets RANK(T_1) + 1$
  \State \Return $T_1$
\EndFunction
\end{algorithmic}

The $LINK$ operation takes $O(1)$ time.

\subsubsection*{Link operation in C++}

\subsubsection*{Link operation in Python}
For the `left child, right sibling' approach, the Python version of $LINK$
algorithm is implemented as below.

\lstset{language=Python}
\begin{lstlisting}
def link(t1, t2):
    if t2.key < t1.key:
        (t1, t2) = (t2, t1)
    t2.sibling = t1.child
    t1.child = t2
    t2.parent = t1
    t1.rank = t1.rank + 1
    return t1
\end{lstlisting}

And we can use Python list to manage the children, so that the 
algoritm turns to be the following.

\begin{lstlisting}
def link(t1, t2):
    if t2.key < t1.key:
        (t1, t2) = (t2, t1)
    t2.parent = t1
    t1.children.insert(0, t2)
    t1.rank = t1.rank + 1
    return t1
\end{lstlisting}



\subsubsection{Find the minimum element in the heap (top)}
Among the forest as the binomial heap, each binomial tree conforms to
heap property that the root contains the minimum element in that tree.
In order to find the minimum element in the heap, we can select the 
smallest root of these trees. Since there are $\lg N$ binomial trees
where $N$ is the element number, this approach takes $O(\lg N)$ time.

For the `left child, right sibling' approach, the algorithm can be
decribed as the following.

\begin{algorithmic}[1]
\Function{FIND-MINUMUM}{$H$}
  \State $T \gets HEAD(H)$
  \State $min \gets \infty$
  \While{$T \ne NIL$}
    \If{$KEY(T) < min$}
      \State $min \gets KEY(T)$
    \EndIf
    \State $T \gets SIBLING(T)$
  \EndWhile
  \State \Return $min$
\EndFunction
\end{algorithmic}

While if we manage the children with collection containers, the link
list iteration is abstract to find the minmum element among the list.

\subsubsection{Find the minimum element in C++}

\subsubsection{Find the minimum element in Python}
`left child, right sibling'

Python list

\subsubsection{Find the minimum element in Haskell}
Explain later together with extract min

\subsubsection{Find the minimum element in Scheme/Lisp}

\subsubsection{Merge two heaps}

\subsubsection{Insert a new element to the heap}

\subsubsection{Extract the minimum element from the heap (pop)}

\subsubsection{Decrease an element}

\subsubsection{Delete an element}

% ================================================================
%                 Fibonacci heaps
% ================================================================
\section{Fibonacci Heaps}
\label{fib-heap}

% ================================================================
%                 Definition
% ================================================================
\subsection{Definition}

% ================================================================
%          Basic Heap operations       
% ================================================================
\subsection{Basic heap operations}

\subsubsection{Find the minimum element in the heap (top)}

\subsubsection{Insert a new element to the heap}

\subsubsection{Merge two heaps}

\subsubsection{Extract the minimum element from the heap (pop)}

\subsubsection{Decrease an element}

\subsubsection{Delete an element}

\subsection{Running times}


% ================================================================
%                 Pairing Heaps
% ================================================================

\section{Pairing Heaps}
\label{pairing-heap}

% ================================================================
%                 Definition
% ================================================================
\subsection{Definition}

% ================================================================
%          Basic Heap operations       
% ================================================================
\subsection{Basic heap operations}

\subsubsection{Find the minimum element in the heap (top)}

\subsubsection{Insert a new element to the heap}

\subsubsection{Merge two heaps}

\subsubsection{Extract the minimum element from the heap (pop)}

\subsubsection{Decrease an element}

\subsubsection{Delete an element}

% ================================================================
%                 Short summary
% ================================================================
\section{Notes and short summary}

% ================================================================
%                 Appendix
% ================================================================
\section{Appendix} \label{appendix}
%\appendix
All programs provided along with this article are free for
downloading.

\subsection{Prerequisite software}
GNU Make is used for easy build some of the program. For C++ and ANSI C programs,
GNU GCC and G++ 3.4.4 are used. 
For Haskell programs GHC 6.10.4 is used
for building. For Python programs, Python 2.5 is used for testing, for
Scheme/Lisp program, MIT Scheme 14.9 is used.

all source files are put in one folder. Invoke 'make' or 'make all'
will build C++ Program. 

There is no separate Haskell main program module, however, it is possible to run the program in GHCi.

\begin{itemize}
\item files

\end{itemize}

download position: http://sites.google.com/site/algoxy/otherheaps/otherheaps.zip

\begin{thebibliography}{99}

\bibitem{K-ary-tree}
K-ary tree, Wikepedia. http://en.wikipedia.org/wiki/K-ary\_tree

\bibitem{CLRS}
Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest and Clifford Stein. ``Introduction to Algorithms, Second Edition''. The MIT Press, 2001. ISBN: 0262032937.

\bibitem{okasaki-book}
Chris Okasaki. ``Purely Functional Data Structures''. Cambridge university press, (July 1, 1999), ISBN-13: 978-0521663502

\bibitem{wiki-pascal-triangle}
Wikipedia, ``Pascal's triangle''. http://en.wikipedia.org/wiki/Pascal's\_triangle

\bibitem{lxy-bheap}
Liu Xinyu. ``Binary heaps with functional and imperative implementation'', https://sites.google.com/site/algoxy/bheap

\end{thebibliography}

\ifx\wholebook\relax \else
\end{document}
\fi
