\ifx\wholebook\relax \else
% ------------------------ 

\documentclass{article}
%------------------- Other types of document example ------------------------
%
%\documentclass[twocolumn]{IEEEtran-new}
%\documentclass[12pt,twoside,draft]{IEEEtran}
%\documentstyle[9pt,twocolumn,technote,twoside]{IEEEtran}
%
%-----------------------------------------------------------------------------
%\input{../../../common.tex}
\input{../../../common-en.tex}

\setcounter{page}{1}

\begin{document}

\fi
%--------------------------

% ================================================================
%                 COVER PAGE
% ================================================================

\title{Sequences, The last brick}

\author{Liu~Xinyu
\thanks{{\bfseries Liu Xinyu } \newline
  Email: liuxinyu95@gmail.com \newline}
  }

\markboth{Sequences}{AlgoXY}

\maketitle

\ifx\wholebook\relax
\chapter{Sequences, The last brick}
\numberwithin{Exercise}{chapter}
\fi

% ================================================================
%                 Introduction
% ================================================================
\section{Introduction}
\label{introduction}
In the first chapter of this book, which introduced binary search tree
as the `hello world' data structure, we mentioned that neither queue
nor array is simple if realized not only in imperative way, but also
in functional approach. In previous chapter, we explained functional
queue, which achieves the similar performance as its imperative counterpart.
In this chapter, we'll dive into the topic of array-like data structures.

We have introduced several data structures in this book so far, and 
it seems that functional approaches typically bring more expressive
and elegant solution. However, there are some areas, people haven't
found competitive purely functional solutions which can match the imperative
ones. For instance, the Ukkonen linear time suffix tree construction
algorithm. another examples is Hashing table. Array is also among them.

Array is trivial in imperative settings, it enables randomly accessing
any elements with index in constant $O(1)$ time. However, this performance
target can't be achieved directly in purely functional settings as
there is only list can be used.

In this chapter, we are going to abstract the concept of array to sequences.
Which support the following features

\begin{itemize}
\item Element can be inserted to or removed from the head of the sequence quickly in $O(1)$ time;
\item Element can be inserted to or removed from the head of the sequence quickly in $O(1)$ time;
\item Support concatenate two sequences quickly (faster than linear time);
\item Support randomly access and update any element quickly;
\item Support split at any position quickly;
\end{itemize}

We call these features abstract sequence properties, and it easy to see
the fact that even array (here means plain-array) in imperative settings
can't meet them all at the same time.

We'll provide three solutions in this chapter. Firstly, we'll introduce
a solution based on binary tree forest and numeric representation;
Secondly, we'll show a catenable list solution; Finally, we'll give
the finger tree solution.

Most of the results are based on Chris, Okasaki's work in \cite{okasaki-book}. 

% ================================================================
%                 Binary random access list
% ================================================================
\section{Binary random access list}
\index{Sequence!Binary random access list}

\subsection{Review of plain-array and list}

Let's review the performance of plain-array and singly linked-list so that we know
how they perform in different cases.

\begin{tabular}{l | c | r}
  \hline
  operation & Array & Linked-list \\
  \hline
  operation on head & $O(N)$ & $O(1)$ \\
  operation on tail & $O(1)$ & $O(N)$ \\
  access at random position & $O(1)$ & average $O(N)$ \\
  remove at given position & average $O(N)$ & $O(1)$ \\
  concatenate & $O(N_2)$ & $O(N_1)$ \\
  \hline
\end{tabular}

Because we hold the head of linked list, operations on head such as insert and remove perform
in constant time; while we need traverse to the end to perform remove or append on tail; Given
a position $i$, it need traverse $i$ elements to access it. Once we are in that position,
removing element from there is just bound to constant time by modifying some pointers. 
In order to concatenate two
linked-lists, we need traverse to the end of the first one, and link it to the second one, which
is bound to the length of the first linked-list;

On the other hand, for array, we must prepare free cell for insert a new element to the head of array, and
we need release the first cell after the first element is removed, all these two operations are
achieved by shifting all the rest elements forward or backward, which costs linear time. While the
operations on the tail of array are trivial constant time ones. Array also support access random
poistion $i$ by nature; However, remove the element at that position cause shifting all elements
after it one position ahead. In order to concatenate two arrays, we need copy all elements from the
second one to the end of the first one (ignore the memory re-allocation details), which is proportion
to the length of the second array.

In the chapter about binomial heaps, we have explained the idea of using forest, which is a list of trees
to design the data structure. It brings us the merit that, for any given number $N$, by representing it
in binary number, we know how many binomial trees need to hold them. That each bit of 1 represent a binomial
tree of that rank of bit. We can go one step ahead, if we have a $N$ nodes binomial heap, for any given
index $1 < i < N$, we can quickly know which binomial tree in the heap hold the $i$-th node.

\subsection{Represent sequence by trees}
\index{Binary Random Access List!Definition}

One solution to realize a random-access sequence is to manage the sequence with a forest of complete binary
trees. Figure \ref{fig:bi-tree-sequence} shows how we attach such trees to a sequence of numbers.

\begin{figure}[htbp]
  \centering
  \includegraphics[scale=1.0]{img/bi-tree-sequence.ps}
  \caption{A sequence of 6 elements can be represented in a forest.} \label{fig:bi-tree-sequence}
\end{figure}

Here two trees $t_1$ and $t_2$ are used to represent sequence $\{x_1, x_2, x_3, x_4, x_5, x_6\}$. 
The size of binary tree $t_1$ is 2. The first two elements $\{x_1, x_2\}$ are leaves of $t_1$;
the size of binary tree $t_2$ is 4. The next foure elements $\{x_3, x_4, x_5, x_6\}$ are leaves
of $t_2$. 

For a complete binary tree, we define the depth as 0 if the tree only has a leaf, 
The tree is denoted as as $t_i$ if its depth is $i+1$. It's obvious that there
are $2^i$ leaves in $t_i$.

For any sequence contains $N$ elements, it can be turned to a forest of compelte binary trees in this manner.
First we represent $N$ in binary number like below.

\be
N = 2^0 e_0 + 2^1 e_1 + ... + 2^M e_M
\ee

Where $e_i$ is either 1 or 0, so $N=(e_M e_{M-1} ... e_1 e_0)_2$. If $e_i \neq 0$, we then need a 
complete binary tree with size $2^i$,  For example in figure \ref{fig:bi-tree-sequence}, as the
length of sequence is 6, which is $(110)2$ in binary. The lowest bit is 0, so we needn't a tree
of size 1; the second bit is 1, so we need a tree of size 2, which has depth of 2; the highest
bit is also 1, thus we need a tree of size 4, which has depth of 3.

This method represents the sequence $\{x_1, x_2, ..., x_N\}$ to a list of trees $\{t_0, t_1, ..., t_M\}$
where $t_i$ is either empty if $e_i = 0$ or a complete binary tree if $e_i = 1$.
We call this representaion as {\em Binary Random Access List}.

We can reused the definition of binary tree, for example, the following Haskell program defines
the binary random access list as well as tree.

\lstset{language=Haskell}
\begin{lstlisting}
data Tree a = Leaf a
            | Node Int (Tree a) (Tree a)  -- size, left, right

type BRAList a = [Tree a]
\end{lstlisting}

The only difference from the typical binary tree is that we augment the size information to the tree.
This enable us to get the size without calculation at every time. For instance.

\begin{lstlisting}
size (Leaf _) = 1
size (Node sz _ _) = sz
\end{lstlisting}

\subsection{Insertion to the head of the sequence}
\index{Binary Random Access List!Insertion}
The new forest representation of sequence enables many operation effectively. For example, the
operation of inserting a new element $y$ in front of sequence can be realized as the following.

\begin{enumerate}
\item Create a tree $t'$, with $y$ as the only one leaf;
\item Examine the first tree in the forest, compare its size with $t'$, if its size is greater than $t'$,
we just let $t'$ be the new head of the forest, since the forest is a linked-list of tree, insert
$t'$ to its head is trivial operation, which is bound to constant $O(1)$ time;
\item Otherwise, if the size of first tree in the forest is equal to $t'$, let's denote this tree
in the forest as $t_i$, we can construct a new binary tree $t'_{i+1}$ by linking $t_i$ and $t'$ as
its left and right children. After that, we recursively try to insert $t'_{i+1}$ to the forest.
\end{enumerate}

TODO: Add figures (step by step insertion) to illustrate the insertion process.

As there are at most $M$ trees in the forest, and $M$ is bound to $O(\lg N)$, so the insertion to
head algorithm is ensured to perform in $O(\lg N)$. 

Let's formalize the algorithm to equations. we define the function of insert a element in front of
a sequence as $insert(S, x)$.

\be
insert(S, x) = insertTree(S, (leaf x))
\ee

This function just wrap element $x$ to a singleton tree with a leaf, and call $insertTree$ to insert
this tree to the forest. Suppose the forest $F=\{ t_1, t_2, ...\}$ if it's not empty, and $F' = \{ t_2, t_3, ...\}$
is the rest of trees without the first one.

\be
insertTree(F, t) =  \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \{ t \} & F = \Phi \\
  \{ t \} \cup F & size(t) < size(t_1) \\
  insertTree(F', link(t, t_1) & otherwise
  \end{array}
\right .
\ee

Where function $link$ create a new tree from two small trees with same size. Suppose function
$tree(s, t_1, t_2)$ create a tree, set its size as $s$, makes $t_1$ as the left child, and $t_2$ as
the right child, linking can be realized as below.

\be
link(t_1, t_2) = tree(size(t_1) + size(t_2), t_1, t_2)
\ee

The relative Haskell programs can be given by translating these equations.

\begin{lstlisting}
cons :: a -> BRAList a -> BRAList a
cons x ts = insertTree ts (Leaf x) 

insertTree :: BRAList a -> Tree a -> BRAList a
insertTree [] t = [t]
insertTree (t':ts) t = if size t < size t' then  t:t':ts
                       else insertTree ts (link t t')

-- Precondition: rank t1 = rank t2
link :: Tree a -> Tree a -> Tree a
link t1 t2 = Node (size t1 + size t2) t1 t2
\end{lstlisting}

Here we use the Lisp tradition to name the function that insert an element before a list as `cons'.

\subsubsection{Remove the element from the head of the sequence}

It's not complex to realize the inverse operation of `cons', which can remove element from the
head of the sequence.

\begin{itemize}
\item If the first tree in the forest is a singleton leaf, remove this tree from the forest;
\item otherwise, we can halve the first tree by unlinking its two children, so the first tree
in the forest becomes two trees, we recursively halve the first tree until it turns to be a 
leaf.
\end{itemize}

TOOD: Add figures to illustrate the remove process step by step.

If we assume the sequence isn't empty, so that we can skip the error handling such as trying 
to remove an element from an empty sequence, this can be expressed with the following equation.
We denote the forest $F = \{t_1, t_2, ... \}$ and the trees without the first one as
$F' = \{ t_2, t_3, ...\}$

\be
extractTree(F) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  (t_1, F') & t_1 {\quad} \mbox{is leaf} \\
  extractTree(\{t_l, t_r\} \cup F') & otherwise
  \end{array}
\right .
\ee

where $\{ t_l, t_r \} = unlink(t_1)$ are the two children of $t_1$.

It can be translated to Haskell programs like below.

\begin{lstlisting}
extractTree (t@(Leaf x):ts) = (t, ts)
extractTree (t@(Node _ t1 t2):ts) = extractTree (t1:t2:ts)
\end{lstlisting}

With this function defined, it's convenient to give `head' and `tail', the former returns
the first element in the sequence, the latter return the rest.

\be
head(S) = key(first(extractTree(S)))
\ee

\be
tail(S) = second(extractTree(S))
\ee

Where function `first' returns the first element in a paired-value (as known as tuple); 
`second' returns the second element respectively. function `key' is used to access the
elements inside a leaf. Below are Haskell programs corresponding to these two euqations.

\begin{lstlisting}
head' ts = x where (Leaf x, _) = extractTree ts
tail' = snd . extractTree
\end{lstlisting}

Note that as `head' and `tail' functions have already been defined in Haskell standard
library, we given them apostrophes to make them distinct. (another option is to hide
the standard ones by importing. We skip the details as they are language specific).

\subsubsection{Random access the element in binary}
\index{Binary Random Access List!Random access}

As trees in the forest help managing the elements in blocks, giving an arbitrary index,
it's easy to locate which tree this element are stored, after that performing a search 
in the tree yields the result. As all trees are binary (more accurate, complete binary
tree), the search is essentially binary search, which is bound to the logarithme
of the tree size. This brings us a faster random access capability than linear search
in linked-list setting.

Given an index $i$, and a sequence $S$, which is actually a forest of trees, the 
algorithm is executed as the following.

\begin{enumerate}
\item Compare $i$ with the size of the first tree $T_1$ in the forest, if $i$ is 
less than the size, the element exists in $T_1$, perform looking up in $T_1$;
\item Otherwise, decrease $i$ by the size of $T_1$, and repeat the previous step
in the rest of the trees in the forest.
\end{enumerate}

This algorithm can be represented as the below equation.

\be
get(S, i) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  lookupTree(T_1, i) & i < size(T_1) \\
  get(S', i-size(T_1)) & otherwise
  \end{array}
\right .
\ee

Where $S' = \{ T_2, T_3, ... \}$ is the rest of trees without the first one in the
forest. Note that we don't handle out of bound error cases, this is left as an exercise
to the reader.

Function `lookupTree' is just a binary search, if the index $i$ is 0, we just return the root
of the tree, otherwise, we halve the tree by unlinking, if $i$ is less than the size
of the halved tree, we recursively perform looking up the left tree, otherwise, we
look up the right tree.

\be
lookupTree(T, i) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  root(T) & i = 0 \\
  lookupTree(left(T)) & i < \lfloor \frac{size(T)}{2} \rfloor \\
  lookupTree(right(T)) & otherwise
  \end{array}
\right .
\ee

Where function `left' returns the left tree $T_l$ of $T$, while `right` returns $T_r$.

The corresponding Haskell program is given as below.

\begin{lstlisting}
getAt (t:ts) i = if i < size t then lookupTree t i
                 else getAt ts (i - size t)

lookupTree (Leaf x) 0 = x
lookupTree (Node sz t1 t2) i = if i < sz `div` 2 then lookupTree t1 i
                               else lookupTree t2 (i - sz `div` 2)
\end{lstlisting}

TODO: Add figures to illustrate this idea.

By using the similar idea, we can update element at any arbitrary position $i$.
We first compare the size of the first tree $T_1$ in the forest with $i$, if it is
less than $i$, it means the element to be updated doesn't exist in the first
tree. We recurisvely examine the next tree in the forest, comparing it with
$i - |T_1|$, where $|T_1|$ represents the size of the first tree. Otherwise
if this size is greater than or equal to $i$, the element is in the tree, 
we halve the tree recursively until to get a leaf, at this stage, we can
replace the element of this leaf with a new one.

\be
set(S, i, x) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \{ updateTree(T_1, i, x) \} \cup S' & i < |T_1| \\
  \{T_1\} \cup set(S', i - |T_1|, x)
  \end{array}
\right .
\ee

Where $S' = \{ T_2, T_3, ...\}$ is the rest of the trees in the forest without
the first one.

Function $setTree(T, i, x)$ performs a tree search and replace the $i$-th element
with the given value $x$.

\be
setTree(T, i, x) =  \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  leaf(x) & i = 0 \land |T| = 1 \\
  tree(|T|, setTree(T_l, i, x), t_r) & i < \lfloor \frac{|T|}{2} \rfloor \\
  tree(|T|, t_l, setTree(T_r, i - \lfloor \frac{|T|}{2} \rfloor, x))
  \end{array}
\right .
\ee

Where $T_l$ and $T_r$ are left and right sub tree of $T$ respectively. The following
Haskell program translates the equation accordingly.

\begin{lstlisting}
setAt :: BRAList a -> Int -> a -> BRAList a
setAt (t:ts) i x = if i < size t then (updateTree t i x):ts
                   else t:setAt ts (i-size t) x

updateTree :: Tree a -> Int -> a -> Tree a
updateTree (Leaf _) 0 x = Leaf x
updateTree (Node sz t1 t2) i x = 
    if i < sz `div` 2 then Node sz (updateTree t1 i x) t2
    else Node sz t1 (updateTree t2 (i - sz `div` 2) x)
\end{lstlisting}

As the nature of complete binary search tree, for a sequence with $N$ elements, which
is represented by binary random
access list, the number of trees in the forest is bound to $O(\lg N)$. Thus it takes
$O(\lg N)$ time to locate the tree for arbitrary index $i$, that contains the element.
the followed tree seach is bound the heights of the tree, which is $O(\lg N)$ as well.
So the total performance of random access is $O(\lg N)$. 

\begin{Exercise}
\begin{enumerate}
\item The random access algorithm given in this section doesn't handle the error such as
out of bound index at all. Modify the algorithm to handle these cases, and implement
it in your favorate programming langauge.

\item It's quite possible to realize the binary random access list in imperative settings,
which is benefited with fast operation on the head of the sequence. the random access
can be realized in two steps: firstly locate the tree, secondly use the capability of
constant random access of array. Write a program to implement it in your favorate imperative
programming language.
\end{enumerate}
\end{Exercise}

\section{Numeric representation for binary random access list}
In previous section, we mentioned that for any sequence with $N$ elements, we can 
represent $N$ in binary so that $N = 2^0e_0 + 2^1e_1 + ... + 2^Me_M$. Where $e_i$
is the $i$-th bit, which can be 0 or 1. If $e_i \neq 0$ it means that there is
a complete binary tree with size $2^i$.

This fact indicates us that there is an explicit relationship between the binary
form of $N$ and the forest.

TODO: Numeric representation.

\section{Cantenable list}
TODO: Cantenable list by Queue

\section{Finger tree}
TODO: Memory overhead of forest solution.
TODO: Finger tree


% ================================================================
%                 Short summary
% ================================================================
\section{Notes and short summary}

TODO: Notes and summary here

% ================================================================
%                 Appendix
% ================================================================

\begin{thebibliography}{99}

\bibitem{okasaki-book}
Chris Okasaki. ``Purely Functional Data Structures''. Cambridge university press, (July 1, 1999), ISBN-13: 978-0521663502

\end{thebibliography}

\ifx\wholebook\relax \else
\end{document}
\fi
