\ifx\wholebook\relax \else
% ------------------------ 

\documentclass{article}
%------------------- Other types of document example ------------------------
%
%\documentclass[twocolumn]{IEEEtran-new}
%\documentclass[12pt,twoside,draft]{IEEEtran}
%\documentstyle[9pt,twocolumn,technote,twoside]{IEEEtran}
%
%-----------------------------------------------------------------------------
%\input{../../../common.tex}
\input{../../../common-en.tex}

\setcounter{page}{1}

\begin{document}

\fi
%--------------------------

% ================================================================
%                 COVER PAGE
% ================================================================

\title{Lists}

\author{Liu~Xinyu
\thanks{{\bfseries Liu Xinyu } \newline
  Email: liuxinyu95@gmail.com \newline}
  }

\markboth{Sequences}{AlgoXY}

\maketitle

\ifx\wholebook\relax
\chapter{Lists}
\numberwithin{Exercise}{chapter}
\fi

% ================================================================
%                 Introduction
% ================================================================
\section{Introduction}
\label{introduction}
This book intensely uses recursive list manipulations in purely functional settings.
List can be treated as a counterpart to arrays in imperative settings, which is
bricks to many algorithms and data structures.

For the readers who are not familiar with functional list manipulation, this appendix
provides a quick reference. All operations listed in this appendix are not only
described in equations, but also implemented in both functional programming languages
as well as imperative languages examples. We also provide a special type of
implementation in C++ template meta programming similar to \cite{moderncxx}
for interesting in next appendix.

Besides the elementary list operations, this appendix also contains explaination of 
some high order function concepts such as mapping, folding etc.


% ================================================================
%                 Binary random access list
% ================================================================
\section{List Definition}
\index{List!Definition}

Like arrays in imperative settings, lists play a critical role in functional setting\footnote{Some 
reader may argue that `lambda calculus plays the most critical role'.
Lambda calculus is somewhat as assembly languages to the computation world, which 
is worthy studying from the essense of computation model to the practical programs.
However, we don't dive into the topic in this book. Users can refer to \cite{mittype}
for detail.}. Lists are built-in supported in some programming languages like Lisp
families and ML families so it needn't explicitly define list in those environment.

List, or more precisely, singly linked-list is a data strucutre that can be described
below.

\begin{itemize}
\item A {\em list} is either empty;
\item Or contains an element and a {\em list}.
\end{itemize}

Note that this definition is recursive. Figure \ref{fig:list-example} illustrates
a list with $N$ nodes. Each node contains two part, a key element and a sub list. The
sub list contained in the last node is empty, which is denoted as 'NIL'.

\begin{figure}[htbp]
        \centering
        \includegraphics[scale=0.8]{img/list-example.ps}
        \caption{A list contains $N$ nodes} \label{fig:list-example}
\end{figure}

This data structure can be explictly defined in programming languages support record
(or compound type) concept. The following ISO C++ code defines list\footnote{We only use
template to parameterize the type of the element in this chapter. Except this point,
all imperative source code are in ANSI C style to avoid language specific features.}.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
struct List {
  T key;
  List* next;
};
\end{lstlisting}

\subsection{Empty list}
It's worth to metion about 'empty' list a bit more in detail. In environment supporting the
nil concept, for example, C or java like programming languages, empty list can have two
different represention. One is the trivial `NIL' (or null, 0 varies from languages);
the other is an non-NIL empty list as $\{ \}$, the latter is typically allocated with
memory but filled with nothing. In Lisp dialects, the empty is commonly written as \verb|'()|.
In ML families, it's written as \verb|[]|. We use $\Phi$ to denote empty list in equations
and use 'NIL' in pseudo code to describe algorithms in this book.

\subsection{Access the element and the sub list}
Given a list $L$, two functions can be defined to access the element stored in it and
the sub list respectively. They are typically denoted as $first(L)$, and $rest(L)$ or
$head(L)$ and $tail(L)$ for the same meaning.
These two functions are named as \verb|car| and \verb|cdr| in Lisp for historic reason
about the design of machine registers \cite{SICP}. In languages support Pattern matching (e.g. ML families)
These two functions are commonly realized by matching the \verb|cons| which we'll introduced
later. for example the following Haskell program:

\lstset{language=Haskell}
\begin{lstlisting}
head (x:xs) = x
tail (x:xs) = xs
\end{lstlisting}

If the list is defined in record syntax like what we did above, these two functions can 
be realized by accessing the record fields \footnote{They can be also named as 'key' and 'next'
or be defined as class methods.}.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
T first(List<T> *xs) { return xs->key; }

template<typename T>
List<T>* rest(List<T>* xs) { return xs->next; }
\end{lstlisting}

In this book, $L'$ is used to denote the $rest(L)$ sometimes, also we uses $l_1$ to represent
$first(L)$ in the context that the list is literately given in form $L = \{ l_1, l_2, ..., l_N\}$.

More interesting, as far as in an environment support recursion, we can define List. The following
example define a list of integers in C++ compile time.

\lstset{language=C++}
\begin{lstlisting}
struct Empty;

template<int x, typename T> struct List {
  static const int first = x;
  typedef T rest;
};
\end{lstlisting}

These line constructs a list of $\{1, 2, 3, 4, 5\}$ in compile time.

\begin{lstlisting}
typedef List<1, List<2, List<3, List<4 List<5, Empty> > > > > A;
\end{lstlisting}

\section{Basic list manipulation}

\subsection{Construction}

The last C++ template meta programming example actually shows literate constraction of a list.
A list can be constructed from an element with a sub list, where the sub list can be empty.
We denote function $cons(x, L)$ as the constructor. This name is used in most Lisp dialects.
In ML families, there are `cons' operator defined as \verb|::|, (in Haskell it's \verb|:|).

We can define \verb|cons| to create a record as we defined above in ISO C++, for example\footnote{
It's often defined as a constructor method for the class template, However, we define it as a standalone
function for illustration purpose.}.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
List<T>* cons(T x, List<T>* xs) {
  List<T>* lst = new List<T>;
  lst->key = x;
  lst->next = xs;
  return lst;
}
\end{lstlisting}

\subsection{Empty testing and length calculating}

Testing if a list is empty is trivial. If the environment contains nil concept, the testing should
also handle nil case. Both Lisp dialects and ML families provide \verb|null| testing functions.
Empty testing can also be realized by pattern-matching with empty list if possible. The following
Haskell program shows such example.

\lstset{language=Haskell}
\begin{lstlisting}
null [] = True
null _ = False
\end{lstlisting}

In this book we will either use $empty(L)$ or $L = \Phi$ where empty testing happens.

With empty testing defined, it's possible to calculate length for a list. 
In imperative settings, \textproc{Length} is ofthen implemented like the following.

\begin{algorithmic}
\Function{Length}{L}
  \State $n \gets 0$
  \While{$L \neq NIL$}
    \State $n \gets n + 1$
    \State $L \gets $ \Call{Next}{$L$}
  \EndWhile
\EndFunction
\end{algorithmic}

This ISO C++ code translates the algorithm to real program.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
int length(List<T>* xs) {
  int n = 0;
  for (; xs; ++n, xs = xs->next);
  return n
}
\end{lstlisting}

However, in purely funcitonal setting, we can't mutate a counter variable. 
the idea is that, if the list is empty, then its size is zero; otherwise, we can recursively 
calculate the length of the sub list, then add it by one to get the length of this list.

\be
length(L) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  0 & L = \Phi \\
  1 + length(L') & otherwise
  \end{array}
\right.
\ee 

Here $L' = rest(L)$ as mentioned above, it's $\{l_2, l_3, ..., l_N\}$ for list contains $N$ elements.
Note that both $L$ and $L'$ can be empty $\Phi$. In this equation, we also use $=$ to test if list
$L$ is empty. In order to know the length of a list, we need traverse all the elements from the head
to the end, so that this algorithm is proprotion to the number of elements stored in the list.
It's a linear $O(N)$ algorithm.

Below are two programs in Haskell and in Scheme/Lisp realize this recursive algorithm.

\lstset{language=Haskell}
\begin{lstlisting}
length [] = 0
length (x:xs) = 1 + length xs
\end{lstlisting}

\lstset{language=Lisp}
\begin{lstlisting}
(define (length lst)
  (if (null? lst) 0 (length (cdr lst))))
\end{lstlisting}

How to testing if two lists are identical is left as exercise to the reader.

\subsection{indexing}

One big difference between array and list (singly-linked list accurately) is that array support
random access. Many programming languages support using \verb|x[i]| to access the $i$-th element
stored in array in constant $O(1)$ time. The index typically starts from 0, but it's not the all case.
Some programming languages using 1 as the first index. In this appendix, we treat index starting
from 0. However, we must traverse the list with
$i$ steps to reach the target element. The traversing is quite similar to the length calculation.
Thus it's commonly expressed as below in imperative settings.

\begin{algorithmic}
\Function{Get-At}{$L, i$}
  \While{$i \neq 0$}
    \State $L \gets $ \Call{Next}{$L$}
  \EndWhile
  \State \Return \Call{First}{$L$}
\EndFunction
\end{algorithmic}

Note that this algorithm doesn't handle the error case such that the index is within the bound
of the list. We assume that $0 \leq i < |L|$, where $|L| = length(L)$. The error handling is left
as exercise to the reader. The following ISO C++ code is a line-by-line translation of this
algorithm.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
T getAt(List<T>* lst, int n) {
  while(n--)
    lst = lst->next;
  return lst->key;
}
\end{lstlisting}

However, in purely functional settings, we turn to resurive traversing instead of while-loop.

\be
getAt(L, i) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  First(L) & i = 0 \\
  getAt(Rest(L), i-1) & otherwise
  \end{array}
\right.
\ee

In order to {\em get the $i$-th element}, the algorithm does the following:
\begin{itemize}
\item if $i$ is 0, then we are done, the result is the first element in the list;
\item Otherwise, the result is to {\em get the $(i-1)$-th element} from the sub-list.
\end{itemize}

This algorithm can be translated to the following Haskell code.

\lstset{language=Haskell}
\begin{lstlisting}
getAt i (x:xs) = if i == 0 then x else getAt i-1 xs
\end{lstlisting}

Note that we are using pattern matching to ensure the list isn't empty, which actually handles
all out-of-bound cases with un-matched pattern error. Thus if $i > |L|$, we finally arrive at
a edge case that the index is $i-|L|$, while the list is empty; On the other hand, if $i < 0$,
minus it by one makes it even farther away from 0. We finally end at the same error that the index 
is some negative, while the list is empty;

The indexing algorithm takes time proportion to the value of index, which is bound to $O(N)$
linear time. 
This section only address the read symatics. How to mutate the element at a given position is
explained in later section.

\subsection{Access the last element}
Although accessing the first element and the rest list $L'$ is trivial, the opposite operations, that
retreiving the last element and the initial sub list need linear time without using a tail pointer. 
If the list isn't empty, we need traverse it till the tail to get these two components. Below are 
their imperative descriptions.

\begin{algorithmic}
\Function{Last}{$L$}
  \State $x \gets $ NIL
  \While{$L \neq$ NIL}
    \State $x \gets $ \Call{First}{$L$}
    \State $L \gets $ \Call{Rest}{$L$}
  \EndWhile
  \State \Return $x$
\EndFunction
\Statex
\Function{Init}{$L$}
  \State $L' \gets $ NIL
  \While{\Call{Rest}{$L$} $\neq$ NIL}
    \State $L' \gets$ \textproc{Append}($L'$, \Call{First}{$L$})
    \State $L \gets $ \Call{Rest}{$L$}
  \EndWhile
  \State \Return $L'$
\EndFunction
\end{algorithmic}

The algorithmis assume that the input list isn't empty, so the error handling is skipped. Note that
the \textproc{Init}() algorithm uses the appending algorithm which will be defined later.

Below are the corresponding ISO C++ implementation. The optimized version by utilizing tail pointer
is left as exercise.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
T last(List<T>* xs) {
  T x; /* Can be set to a special value to indicate empty list err. */
  for (; xs; xs = xs->next)
    x = xs->key;
  return x;
}

template<typename T>
List<T>* init(List<T>* xs) {
  List<T>* ys = NULL;
  for (; xs->next; xs = xs->next)
    ys = append(ys, xs->key);
  return ys;
}
\end{lstlisting}

While these two algorithm can be implemented in purely recursive manner as well. When we want to access
{\em the last element}. 

\begin{itemize}
\item If the list contains only one element (the rest sub-list is empty), the result is this very element;
\item Otherwise, the result is {\em the last element} of the rest sub-list.
\end{itemize}

\be
last(L) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  First(L) & Rest(L) = \Phi \\
  last(Rest(L)) & otherwise
  \end{array}
\right.
\ee

The simliar approach can be used to {\em get a list contains all elements except for the last one}.

\begin{itemize}
\item The edge case: If the list contains only one element, then the result is a empty list;
\item Otherwise, we can first {\em get a list contains all elements except for the last one} from the rest sub-list, then
construct the final result from the first element and this intermediate result.
\end{itemize}

\be
init(L) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \Phi & L' = \Phi \\
  cons(l_0, init(L')) & otherwise
  \end{array}
\right.
\ee

Here we denote $l_0$ as the first element of $L$, and $L'$ is the rest sub-list. This recursive algorithm needn't
use appending, It actually construct the final result list from right to left. We'll introduce a high-level concept
of such kind of computation later in this appendix.

Below are Haskell programs implement $last()$ and $init()$ algorithms by using pattern matching.

\lstset{language=Haskell}
\begin{lstlisting}
last [x] = x
last (_:xs) = last xs

init [x] = []
init (x:xs) = x : init xs 
\end{lstlisting}

Where \verb|[x]| matches the singleton list contains only one element, while \verb|(_:xs)| matches any non-empty list,
and the underscore (\verb|_|) is used to indicate that we don't care about the element. For the detail of pattern matching,
readers can refer to any Haskell tutorial materials, such as \cite{learn-haskell}.

\subsection{Reverse indexing}
Reverse indexing is a general case for $last()$, finding the $i$-th element in a singly-linked list
with the minimized memory spaces is interesting, and this problem is often used in technical interview
in some companies. A naive implementation takes 2 rounds of traversing, the first round is to determine
the length of the list $N$, then, calculate the left-hand index by $N - i - 1$. Finally a second round
of traverse is used to access the element with the left-hand index. This idea can be give as the 
following equation.

\[
  getAtR(L, i) = getAt(L, length(L) - i -1)
\]

There exists better imperative solution. For illustration purpose, we omit the error cases such
as index is out-of-bound etc. The idea is to keep two pointers $p_1, p_2$, with the distance
of $i$ between them, that $rest^i(p_2) = p_1$, where $rest^i(p_1)$ means apply $rest()$ function
$i$ times. It says that succeeds $i$ steps from $p_2$ gets $p_1$. We can start $p_2$ from the head
of the list and advance the two pointers in parallel till one of them ($p_1$) arrives at the end
of the list. At that time point, pointer $p_2$ exactly arrived at the $i$-th element from right.
Figure \ref{fig:list-rindex} illustrates this idea.

\begin{figure}[htbp]
    \centering
    \subfloat[$p_2$ starts from the head, which is behind $p_1$ in $i$ steps.]{\includegraphics[scale=0.8]{img/list-rindex.ps}} \\
    \subfloat[When $p_1$ reaches the end, $p_2$ points to the $i$-th element from right.]{\includegraphics[scale=0.8]{img/list-rindex-2.ps}}
    \caption{Double pointers solution to reverse indexing.} \label{fig:list-rindex}
\end{figure}

It's straightforward to realize the imperative algorithm based on this `double pointers' solution.

\begin{algorithmic}
\Function{Get-At-R}{$L, i$}
  \State $p \gets L$
  \While{$i \neq 0$}
    \State $L \gets $ \Call{Rest}{$L$}
    \State $i \gets i - 1$
  \EndWhile
  \While{\Call{Rest}{$L$} $\neq$ NIL}
    \State $L \gets$ \Call{Rest}{$L$}
    \State $p \gets$ \Call{Rest}{$p$}
  \EndWhile
  \State \Return \Call{First}{$p$}
\EndFunction
\end{algorithmic}

The following ISO C++ code implements the `double pointers' right indexing algorithm.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
T getAtR(List<T>* xs, int i) {
  List<T>* p = xs;
  while(i--)
    xs = xs->next;
  for(; xs->next; xs = xs->next, p = p->next);
  return p->key;
}
\end{lstlisting}

The same idea can be realized recursively as well. If we want to access the $i$-th element of list $L$, we
can examine the two lists $L$ and $S=\{l_i, l_{i+1}, ..., l_N\}$ simulaneously, where $S$ is a sub-list
of $L$ without the first $i$ elements.

\begin{itemize}
\item The edge case: If $S$ is a singleton list, then the $i$-th element from right is the first element in $L$;
\item Otherwise, we drop the first element from $L$ and $S$, and recursively examine $L'$ and $S'$.
\end{itemize}

This algorithm description can be formalized as the following equations.

\be
getAtR(L, i) = examine(L, drop(i, L))
\ee

Where function $examine(L, S)$ is defined as below.

\be
examine(L, S) =  \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  first(L) & |S| = 1 \\
  examine(rest(L), rest(S)) & otherwise
  \end{array}
\right.
\ee

We'll explain the detail of $drop()$ function in later section about list mutating operations. Here it can
be implemented as repeatedly call $rest()$ with specified times.

\[
drop(n, L) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  L & n = 0 \\
  drop(n - 1, rest(L)) & otherwise
  \end{array}
\right.
\]

Translating the equations to Haskell yeilds this example program.

\lstset{language=Haskell}
\begin{lstlisting}
atR :: [a] -> Int -> a
atR xs i = get xs (drop i xs) where
  get (x:_) [_] = x
  get (_:xs) (_:ys) = get xs ys
  drop n as@(_:as') = if n == 0 then as else drop (n-1) as'
\end{lstlisting}

Here we use dummy variable \verb|_| as the placeholders for components we don't care.

\subsection{Mutating}

Strictly speaking, we can't mutate the list at all in purely funcitonal settings. What we mutate in
imperative settings is just creation of new list. Almost all functional environments support gabbage
collection, the orginal list may either persisited for reusing, or released (dropped) at sometime \cite{okasaki-book}(Chapter 2).

\subsubsection{Appending}
Function $cons$ can be viewed as building list by insertion element always on head. If we chaines multiple
$cons$ operation, it repeatedly constructs a list from right to the left. Appending on the other hand,
is an operation adding element to the tail. Compare to $cons$ which is trivial constant time $O(1)$ operation,
We must traverse the whole list to locate the appending position, it means that appending is bound to
$O(N)$, where $N$ is the length of the list. In order to speed up the appending, imperative implementation
typically use a field (variable) to record the tail position of a list, so that the traversing can be
avoided. However, in purely functional settings we can't use such `tail' pointer. The appending has to
be realized in recursive manner.

\be
append(L, x) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \{ x \} & L = \Phi \\
  cons(first(L), append(rest(L), x)) & otherwise
  \end{array}
\right.
\ee

That the algoritm handles two different appending cases.
\begin{itemize}
\item If the list is empty, the result is a singleton list contains $x$, which is the element to be appended. The singleton list denotion $\{ x \} = cons(x, \Phi)$, is a simplified form of $cons$ the element with an empty list $\Phi$;
\item Otherwise, for the none-empty list, the result can be achieved by first appending the element $x$ to the rest sub-list, then construct the first element of $L$ with the recursive appending result. 
\end{itemize}

For the none-trivial case, if we denote $L= \{l_0, l_1, ... \}$, and $L' = \{ l_2, l_3, ...\}$ the equation can be
written as.

\be
append(L, x) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \{ x \} & L = \Phi \\
  cons(l_0, append(L', x)) & otherwise
  \end{array}
\right.
\ee

We'll use both forms in the rest of this appendix.

The following Scheme/Lisp program implements this algorithm.

\lstset{language=Lisp}
\begin{lstlisting}
(define (append lst x)
  (if (null? lst) 
      (list x) 
      (cons (car lst) (append (cdr lst) x))))
\end{lstlisting}

Even without the tail pointer, it's possible to traverse the list imperatively and append the element at the end.

\begin{algorithmic}
\Function{Append}{$L, x$}
  \If{$L = $ NIL}
    \State $L \gets$ \Call{Cons}{$x$, NIL}
  \Else
    \While{\Call{Rest}{$L$} $\neq$ NIL}
      \State $L \gets$ \Call{Rest}{$L$}
    \EndWhile
    \State \Call{Rest}{$L$} $\gets$ \Call{Cons}{$x$, NIL}
  \EndIf
  \State \Return $L$
\EndFunction
\end{algorithmic}

The following ISO C++ programs implements this algorithm. How to utilize a tail field to speed up the appending
is left as exercise to the reader for interesting.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
List<T>* append(List<T>* xs, T x) {
  List<T> *tail, *head;
  for (head = tail = xs; xs; xs = xs->next)
    tail = xs;
  if (!head)
    head = cons<T>(x, NULL);
  else
    tail->next = cons<T>(x, NULL);
  return head;
}
\end{lstlisting}

\subsubsection{Mutate element at given position}

Although we have defined random access algorithm $getAt(L, i)$, we can't just mutate the element returned
by this function in a sense of purely functional settings. It's quite common to provide reference symantics
in imperative programming languages and in some `almost' functional environment. Readers can refer to \cite{mittype}
for detail. For example, the following ISO C++ example returns a reference instead of a value in indexing program.

\lstset{language=C++}
\begin{lstlisting}
template<typename T>
T& getAt(List<T>* xs, int n) {
  while (n--)
    xs = xs->next;
  return xs->key;
}
\end{lstlisting}

So that we can use this function like this to mutate the 2nd element.

\begin{lstlisting}
List<int>* xs = cons(1, cons(2, cons<int>(3, NULL)));
getAt(xs, 1) = 4;
\end{lstlisting}

In an impure functional environment, such as Scheme/Lisp, to set the $i$-th element to a given value can
be implemented by mutate the referenced cell directly as well.

\lstset{language=Lisp}
\begin{lstlisting}
(define (set-at! lst i x)
  (if (= i 0)
      (set-car! lst x)
      (set-at! (cdr lst) (- i 1) x)))
\end{lstlisting}

This program first checks if the index $i$ is zero, if so, it mutate the first element of the list to
given value $x$; otherwise, it deduces the index $i$ by one, and tries to mutate the rest of the 
list at this new index with value $x$. This function doesn't return meaningful value. It is for use
of side-effect. For instance, the following code mutates the 2nd element in a list.

\begin{lstlisting}
(define lst '(1 2 3 4 5))
(set-at! lst 1 4)
(display lst)

(1 4 3 4 5)
\end{lstlisting}

In order to realize a purely functional $setAt(L, i, x)$ algorithm, we need avoid directly mutating the cell,
but creating a new one:

\begin{itemize}
\item Edge case: If we want to set the value of the first element ($i = 0$), we construct a new list, with the
new value and the sub-list of the previous one;
\item Othewise, we construct a new list, with the previous first element, and a new sub-list, which has the ($i-1$)-th
element set with the new value.
\end{itemize}

This recurisve description can be formalized by the following equation.

\be
setAt(L, i, x) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  cons(x, L') & i = 0 \\
  cons(l_0, setAt(L', i-1, x)) & otherwise
  \end{array}
\right.
\ee

Comparing the below Scheme/Lisp implementation to the previous one reveals the difference from imperative mutating.

\lstset{language=Lisp}
\begin{lstlisting}
(define (set-at lst i x)
  (if (= i 0)
      (cons x (cdr lst))
      (cons (car lst) (set-at (cdr lst) (- i 1) x))))
\end{lstlisting}

Here we skip the error handling for out-of-bound error etc. again. Similar to the random access algorithm, the
performance is bound to linear time, as traverse is need to locate the position to set the value.

\subsubsection{insertion}

There are two symatics about list insertion. One is to insert an element at a given position, which can be denoted
as $insert(L, i, x)$. The algorithm is close to $setAt(L, i, x)$; The other is to insert an element to a sorted list,
so that the the result list is still sorted.

Let's first consider how to insert an element $x$ at a given position $i$. The obvious thing is that we need firstly traverse
$i$ elements to get to the position, the rest of work is to construct a new sub-list with $x$ being the head of this
sub-list. Finally, we construct the whole result by attaching this new sub-list to the end of the first $i$ elements.

The algorithm can be described accordingly to this idea. If we want to insert an element $x$ to a list $L$ at $i$.

\begin{itemize}
\item Edge case: If $i$ is zero, then the insertion turns to be a trivial `cons' operation -- $cons(x, L)$;
\item Otherwise, we recursively {\em insert} $x$ to the sub-list $L'$ at position $i-1$; then construct the first
element with this result.
\end{itemize}

Below equation formalizes the insertion algorithm.

\be
insert(L, i, x) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  cons(x, L) & i = 0 \\
  cons(l_0, insert(L', i-1, x)) & otherwise
  \end{array}
\right.
\ee

The following Haskell program implements this algorithm.

\lstset{language=Haskell}
\begin{lstlisting}
insert xs 0 y = y:xs
insert (x:xs) i y = x : insert xs (i-1) y
\end{lstlisting}

This algorithm doesn't handle the out-of-bound error. However, we can intepret the
case, that the position $i$ exceeds the length of the list as appending. Readers can considering about
it in the exercise of this section.

If the list $L$ is soreted, that is for any position $0 \leq i \leq j \leq N$, we have $l_i \leq l_j$.
We can design an algorithm which inserts a new element $x$ to the list, so that the result list is still sorted.

\be
insert(L, x) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  cons(x, \Phi) & L = \Phi \\
  cons(x, L) & x < l_0 \\
  cons(l_0, insert(L', x)) & otherwise
  \end{array}
\right.
\ee

The idea is that to insert an element $x$ to a sorted list $L$.

\begin{itemize}
\item If either $L$ is empty or $x$ is less than the first element in $L$, we just put $x$ in front of $L$ to construct the result;
\item Otherwise, we recursively insert $x$ to the sub-list $L'$.
\end{itemize}

The following Haskell program implements this algorithm. Note that we use $\leq$, to determine the ordering. Actually this 
constrait can be loss to the strict less ($<$), that if elements can be compare in terms of $<$, we can design a program
to insert element so that the result list is still sorted. Readers can refer to the chatper of sorting for details about
ordering.

\lstset{language=Haskell}
\begin{lstlisting}
insert [] y = [y]
insert (x:xs) y = if y <= x then y:x:xs else x : insert xs y
\end{lstlisting}

Since the algorithm need compare the elements one by one, it's also a linear time algorithm. With insertion defined, it's
possible to implement insertion sort by repeatedly inserting element to an empty list.

\be
sort(L) = \left \{
  \begin{array}
  {r@{\quad:\quad}l}
  \Phi & L = \Phi \\
  insert(l_0, sort(L')) & otherwise
  \end{array}
\right.
\ee

\subsection{deletion}

\subsection{concatenate}

\subsection{sum and product}

\subsection{maximum and minimum}

\begin{Exercise}
\begin{itemize}
\item Given two lists $L_1$ and $L_2$, design a algorithm $eq(L_1, L_2)$ to test if they are equal to each other.
Here equality means the lengths are same, and at the same time, every elements in both list are identical.
\item Consider varies of options to handle the out-of-bound error case when randomly access the element in list. Realize
them in both imperative and functional programming languages. Compare the solutions based on exception and error code.
\item Augment the list with a `tail' field, so that the appending algorithm can be realized in constant $O(1)$ time but
not linear $O(N)$ time. Feel free to choose your favorite imperative programming language. Please don't refer to the
example source code along with this book before you try it.
\item With `tail' field augmented to list, for which list operations this field must be updated? How it affects to the
performance?
\item Handle the out-of-bound case in insertion as appending.
\item Write the insertion sort algorithm by only using less than ($<$).
\end{itemize}
\end{Exercise}

\section{Transformation}

\subsection{mapping and for-each}

\subsection{reverse}

\section{Extract sub-lists}

\section{take and drop}

\section{split at and breaking and grouping}

\section{Folding}

\subsection{folding from left}

\subsection{folding from right}

\subsection{folding in practice}

\subsubsection{concatenate a list of list}

\section{Searching and matching}

\subsection{Existence testing}

\subsection{Looking up}

\subsection{finding and filtering}



\subsection{Matching}

prefix, postfix, and infix

\section{zipping and unzipping}

% ================================================================
%                 Short summary
% ================================================================
\section{Notes and short summary}
...

% ================================================================
%                 Appendix
% ================================================================

\begin{thebibliography}{99}

\bibitem{moderncxx}
Andrei Alexandrescu. ``Modern C++ design: Generic Programming and Design Patterns Applied''. Addison Wesley February 01, 2001, ISBN 0-201-70431-5

\bibitem{mittype}
Benjamin C. Pierce. ``Types and Programming Languages''. The MIT Press, 2002. ISBN:0262162091

\bibitem{SICP}
Harold Abelson, Gerald Jay Sussman, Julie Sussman. ``Structure and Interpretation of Computer Programs, 2nd Edition''. MIT Press, 1996, ISBN 0-262-51087-1

\bibitem{okasaki-book}
Chris Okasaki. ``Purely Functional Data Structures''. Cambridge university press, (July 1, 1999), ISBN-13: 978-0521663502

\bibitem{learn-haskell}
Miran Lipovaca. ``Learn You a Haskell for Great Good! A Beginner's Guide''. No Starch Press; 1 edition April 2011, 400 pp. ISBN: 978-1-59327-283-8

\end{thebibliography}

\ifx\wholebook\relax \else
\end{document}
\fi

% LocalWords:  typedef struct typename
